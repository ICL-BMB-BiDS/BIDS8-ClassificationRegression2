{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f771910a",
   "metadata": {},
   "source": [
    "Aim to complete as much of this tutorial on your own *before* coming to the practical session.\n",
    "\n",
    "Use the practical session to get help for any aspect you do not understand or were unable to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e0810-8aeb-4847-ad9e-1118a658bb8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification and Regression 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb3e6b-020b-482c-81c5-36c5f344b28a",
   "metadata": {},
   "source": [
    "Learning objectives\n",
    "1. Apply SVC to data sets to predict binary outcome measures (groups) using the popular python library [sklearn](https://scikit-learn.org/stable/)\n",
    "2. Explore different metrics to evaluate the model performance in classification settings and visualise variable importance\n",
    "3. Investigate the effect of using different types of kernels on the model performance\n",
    "4. Apply SVMs in a regression setting using SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ac8cb",
   "metadata": {},
   "source": [
    "## Import specific packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb867c-bc9b-4a11-a226-354010264890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC, NuSVC, SVR, NuSVR, LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score, f1_score, accuracy_score, balanced_accuracy_score, classification_report, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7913b9",
   "metadata": {},
   "source": [
    "## Load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e98268-4f40-4dc0-814c-78ad92d953db",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_metabol_plasma = pd.read_excel('../Data-main/diabetes_metabolomics_plasma.xlsx')\n",
    "diabetes_metabol_saliva = pd.read_excel('../Data-main/diabetes_metabolomics_saliva.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eddbdb",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d60449-a831-403d-aa3f-ed7955faddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(diabetes_metabol_plasma)\n",
    "display(diabetes_metabol_plasma.T2D.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c9fef-59d3-4ffe-bca5-5916c7e92b2e",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your CID here, or date of birth, or another number of your choosing to use as random state\n",
    "CID = 0\n",
    "\n",
    "# remember to check the documentation of each algorithm if setting the random_state is needed\n",
    "# for this tutorial and all upcoming tutorials..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f83ea-6df8-4732-b628-812595d75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(diabetes_metabol_plasma.iloc[:, 6:], diabetes_metabol_plasma.T2D, test_size=0.2, random_state=CID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb754043-0e02-43e2-8f69-eda42b9bf668",
   "metadata": {},
   "source": [
    "If you `display(X_test_unscaled, y_test)` you will notice that the function retains the index values for each sample, so you can check that the splitting and the respective `y` targets (T2D status) have been split correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45772c-d98a-4254-ae97-ed6a46fdc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data with standard scaling (0 mean and unit variance)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b65cb9-b4b9-4a19-8f38-95056dbd2486",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25287805-6d19-44c6-9aab-d0545ca65987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier with the standard parameters set by sklearn \n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "# Fit your first SVC model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set \n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b883b3-5f1e-4e15-8966-75e22c266ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try with a linear kernel...\n",
    "clf_linear = LinearSVC(C=1.4)\n",
    "\n",
    "# Fit your first SVC model \n",
    "clf_linear.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set \n",
    "y_pred_linear = clf_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1783a-614d-476f-a810-0428d4c116e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy metrics\n",
    "\n",
    "We will explore a variety of metrics commonly used to evaluate classification models. The functions we will use are all found under `sklearn.metrics`. Please take some time to read the [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html) and familiarise yourself with the differences between accuracy, AUC (Area Under the ROC Curve), f1 score, precision, recall etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986f953-4833-4ba4-9b14-06bb6b78ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "display(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3eaae-5006-42e4-b68b-8c73baf95472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "display(cm)\n",
    "sns.heatmap(cm, annot=True, ax=ax, cmap='Greens'); #annot=True to annotate cells\n",
    "ax.set_xlabel('Predicted status')\n",
    "ax.set_ylabel('True status')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# in this case 0 is Healthy and 1 is T2D samples therefore we can name the labels \n",
    "ax.xaxis.set_ticklabels(['Healthy', 'T2D'])\n",
    "ax.yaxis.set_ticklabels(['Healthy', 'T2D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee059d4-6321-4c51-a1e1-0251f55370bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, clf.decision_function(X_test), average='macro')\n",
    "display(auc)\n",
    "\n",
    "auc = roc_auc_score(y_test, clf.decision_function(X_test), average='micro')\n",
    "display(auc)\n",
    "\n",
    "auc = roc_auc_score(y_test, clf.decision_function(X_test), average='weighted')\n",
    "display(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c310f-51cd-4688-878f-31ecf4158e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_curve(y_test, clf.decision_function(X_test))\n",
    "display(roc)\n",
    "fpr = roc[0]\n",
    "tpr = roc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e6ad6-df09-4b5b-826f-9015d3ed803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(fpr,tpr,lw=2,label=\"ROC curve (area = %0.2f)\" % auc, ci=None)\n",
    "sns.lineplot([0, 1], [0, 1], lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC\")\n",
    "plt.legend(loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4a94-8f18-4ec2-ae16-b9c9e0bf6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "display(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a9150-152e-442e-8a63-4218f21e8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calculating the above metrics for the Linear kernel predictions...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf56f2-b08a-467a-9ea5-510da2938edc",
   "metadata": {},
   "source": [
    "### Parameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a8c56-20a6-436c-9285-a89d28bfac3a",
   "metadata": {},
   "source": [
    "You will notice that the `SVC()` function used above contains a number of parameters that need to be set by the user in order to optimise the model. The parameter `C` functions as a regularisation parameter and non-linear kernels (like the radial basis function (`rbf`) that we used above) require the `gamma` parameter which defines the kernel coefficient. For a more detailed explanation, you can study the kernel functions further on the [documentation](https://scikit-learn.org/stable/modules/svm.html#svm-kernels).\n",
    "\n",
    "We will use the [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) function to find the optimal parameters that maximise the accuracy of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905d258-a55a-4778-864b-51444ff2d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters range or set more than one sklearn-given options\n",
    "param_grid = {'C': np.logspace(-2, 10, 13), \n",
    "              'gamma': ['scale', 'auto'], \n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "             }\n",
    "\n",
    "gridcv = GridSearchCV(SVC(), param_grid, refit=True, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "\n",
    "# fit the model for grid search \n",
    "gridcv.fit(X_train, y_train) \n",
    " \n",
    "# display best parameters after tuning \n",
    "display(gridcv.best_params_) \n",
    "gridcv_pred = gridcv.predict(X_test) \n",
    "   \n",
    "# classification report \n",
    "print(classification_report(y_test, gridcv_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b7818-bd87-4cb6-ba98-c8ea9ab57462",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a72c4-4e54-4155-bb29-6b4f5d9ee5e3",
   "metadata": {},
   "source": [
    "Ofter when we have a lot of features in our dataset we want to eliminate those that do not contribute much to the classification, or select the featues that drive the classification.One of the most used feature selection techniques is __Recursive Feature Elimination (RFE)__. Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. To find out more about RFE or other feature selection methods, read thourgh the [documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection). Here we will use the cross-validation RFE function [`RFECV()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV).   \n",
    "\n",
    "We will use the [`NuSVC()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html) function which is similar to the previously used SVC but uses the `nu` parameter to control the number of support vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1043f26b-4152-4236-a0eb-445f9eeda419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier of choice and its parameters\n",
    "clf = NuSVC(\n",
    "    nu=0.5, \n",
    "    kernel='linear', \n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "# create the rfe object\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    min_features_to_select=1,\n",
    ")\n",
    "\n",
    "%time rfecv.fit(X_train, y_train)\n",
    "\n",
    "display('optimal n of features: %d' % rfecv.n_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be461c-5e7c-4d70-bba9-52e91c843c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the change in accuracy when looking at the step-wise different number of features\n",
    "plt.xlabel(\"number of features selected\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "for i in range(0,5):\n",
    "    sns.lineplot(\n",
    "        range(1, len(rfecv.grid_scores_) + 1),\n",
    "        rfecv.grid_scores_[:, i],\n",
    "        label=f'CV fold {i+1}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35499255-9fe5-45c4-882c-80e1681123a1",
   "metadata": {},
   "source": [
    "### __Your turn...__\n",
    "\n",
    "Try defining a new classifier with the [`LinearSVC()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) function and perform a grid search to decide the best `C` values for the model. \n",
    "\n",
    "Then apply RFE cross-validation and use the optimal number of features and the selected features to run your model. _Hint_: to get the selected features use the `rfecv.support_` attribute which gives you a mask [True (selected), False (not selected)] array of all the features.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115fead-f17a-4fc4-80ab-36a0b39f8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before redifining your new classifier below is a brief example of\n",
    "# how to use the rfecv.support_ object: \n",
    "\n",
    "# display(rfecv.support_) # unhash this to see the format described above \n",
    "\n",
    "# if you just want to display the feature names (without the dataframe slice + their values across samples):\n",
    "display(diabetes_metabol_plasma.iloc[:, 6:].columns[rfecv.support_])\n",
    "\n",
    "# if you want to get the dataframe of samples with the values for these specific features \n",
    "# you can either use the feature names printed above \n",
    "features_selected = diabetes_metabol_plasma.iloc[:, 6:].columns[rfecv.support_].tolist()\n",
    "display(diabetes_metabol_plasma.iloc[:, 6:][features_selected]) \n",
    "\n",
    "# OR you can get the indeces of the TRUE values in the rfe.support_ array and use those indeces to slice the dataframe\n",
    "# this is more generalisable code that you can use in order to get indeces of elements in a list \n",
    "feature_indeces = []\n",
    "for i, feat in enumerate(rfecv.support_): \n",
    "    if feat == True:\n",
    "        feature_indeces.append(i)\n",
    "display(feature_indeces)      \n",
    "display(diabetes_metabol_plasma.iloc[:,6:].iloc[:, feature_indeces]) \n",
    "\n",
    "# notice both dataframes displayed are the same! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77732eca-b143-4861-8048-6725b188ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier \n",
    "\n",
    "# set the parameter grid \n",
    "\n",
    "# create the rfe object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070439f-a529-4a05-9dbd-c1af8d4a1c26",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "Load an appropriate dataset with continuous target variables and repeat the above parts of the tutorial for Support Vector Regression models.\n",
    "\n",
    "The [`SVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) function requires the same parameters that you encountered before (C, kernel, gamma (for non-linear kernels) etc) with an additional parameter `epsilon` being added. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value. Similar to the classification objects we used above, sklearn defines [`NuSVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR) and [`LinearSVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR) objects for regression tasks as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c700f-33ae-4063-a6a2-50da3945ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets; the BMI values which will be our target (y) for this regression example \n",
    "X_train_reg_unscaled, X_test_reg_unscaled, y_train_reg, y_test_reg = train_test_split(diabetes_metabol_plasma.iloc[:,6:], diabetes_metabol_plasma.BMI, test_size=0.2, random_state=56)\n",
    "\n",
    "# scaling \n",
    "scaler = StandardScaler()\n",
    "X_train_reg = scaler.fit_transform(X_train_reg_unscaled)\n",
    "X_test_reg = scaler.transform(X_test_reg_unscaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60515a99-1784-45a3-83ad-fc750b8caacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the regressor with the default sklearn parameters \n",
    "regr = SVR() # here the epsilon value is the default 0.1\n",
    "\n",
    "regr.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = regr.predict(X_test_reg)\n",
    "\n",
    "r2 = r2_score(y_test_reg, y_pred_reg) # another metric used in regression is Mean Squared Error (MSE)\n",
    "display(r2)\n",
    "\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "display(mse)\n",
    "\n",
    "# try to plot these results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aab975-f9e5-4544-9910-1b86ea8c8152",
   "metadata": {},
   "source": [
    "_Hint:_ sklearn has a few good examples for plotting results -- a few to look at is this [comparison of kernel ridge regression and SVR](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_kernel_ridge_regression.html#sphx-glr-auto-examples-miscellaneous-plot-kernel-ridge-regression-py) and the examples on [model complexity influence](https://scikit-learn.org/stable/auto_examples/applications/plot_model_complexity_influence.html#sphx-glr-auto-examples-applications-plot-model-complexity-influence-py)\n",
    "\n",
    "In addition make sure to investigate the different metrics used to evaluate regression models, some examples include the r2 score, mean squared error, mean absolute error, and others.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
